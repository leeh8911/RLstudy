<요약>
1. 다이내믹 프로그래밍의 한계
	* DP는 ::학습이 아니고:: 큰 문제를 빠르게 해결하기 위한 계산법
	* 계산의 복잡도 : 모든 경우의 수에 대한 계산이 이루어지기 때문에, 가능한 `상태`가 많아질 수록 계산해야 하는 양은 기하급수적으로 증가(ex, 바둑)
	* 차원의 저주 : ???
	* 환경에 대한 완벽한 정보가 필요 : 이전까지는 보상, 상태 변환 확률(::환경의 모델::)을 정확히 안다는 `가정`하에 풀었지만, 실제로는 알기 어려움. 
2. 모델 없이 학습하는 강화학습
	* 환경의 모델은 `상태 변환 확률`과 `보상`
	* 모델이란 시스템에 어떠한 입력이 들어왔을 때, 어떤 출력을 내보내는지에 대한 방정식
	* 모델을 정확히 알기 어려운 상황에서 입/출력 사이의 관계를 알아내기 위한 방법
		1. 할 수 있는 선에서 정확히 모델링을 한 다음 모델링 오차에 대한 부분을 실험적으로 조정
		2. 모델 없이 환경과의 상호작용을 통해 입/출력 사이의 관계를 학습
	* (1)은 고전적인 방법으로 시스템의 안정성은 보장이 되나, 문제가 어려워 질 수록 한계가 있음
	* (2)는 학습의 개념이 들어감. 모든 상황에서 동일하게 작동한다고 보장할 수 없지만, 복잡한 문제에 대해서 모델이 필요 없음
3. 정리

<인상깊은 점>
* 앞선 차수별 요약에서 매번 지금까지 공부하고 있는 내용들이 `학습`보다는 `판단`에 가까운 것 같다는 이야기를 했는데, 책에서 DP에 대한 한계점과 특징에 대해 내 생각과 유사하게 말한 것이 흥미로웠다

<질문>
* 차원의 저주가 하고자 하는 말이 이해가 잘 안감
